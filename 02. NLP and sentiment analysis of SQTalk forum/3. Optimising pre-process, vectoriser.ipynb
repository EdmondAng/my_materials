{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* [1. Optimise Pre-Processing & Vectoriser](#1.-Optimise-Pre-Processing-&-Vectoriser)\n",
    "* [2. Imports](#2.-Imports)\n",
    "* [3. Data Cleaning & Preparation](#3.-Data-Cleaning-&-Preparation)\n",
    "* [4. Model Fit & Predict](#4.-Model-Fit-&-Predict)\n",
    "* [5. Remarks](#5.-Remarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Optimise Pre-Processing & Vectoriser\n",
    "---\n",
    "The objective is to compare the following models to determine the best combination of pre-processing and vectoriser, before deciding on the best model to use:\n",
    "\n",
    "|                | Baseline Model          | Alternate 1             | Alternate 2                                       | Alternate 3                                       |\n",
    "|----------------|-------------------------|-------------------------|---------------------------------------------------|---------------------------------------------------|\n",
    "| Pre-processing | - Basic cleaning<br>- Stem        | - Basic cleaning<br>- Stem       | - Basic cleaning<br>- Stem<br>- Remove duplicated sentences | - Basic cleaning<br>- Stem<br>- Remove duplicated sentences |\n",
    "| Vectoriser     | CountVectoriser         | TFIDF                   | CountVectoriser                                   | TFIDF                                             |\n",
    "| Model          | Multinomial Naive Bayes | Multinomial Naive Bayes | Multinomial Naive Bayes                           | Multinomial Naive Bayes                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:39:59.886784Z",
     "iopub.status.busy": "2023-01-27T07:39:59.886264Z",
     "iopub.status.idle": "2023-01-27T07:39:59.894120Z",
     "shell.execute_reply": "2023-01-27T07:39:59.892840Z",
     "shell.execute_reply.started": "2023-01-27T07:39:59.886730Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier as ovr\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,classification_report, roc_auc_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Cleaning & Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:31:39.333593Z",
     "iopub.status.busy": "2023-01-27T07:31:39.333162Z",
     "iopub.status.idle": "2023-01-27T07:31:39.817233Z",
     "shell.execute_reply": "2023-01-27T07:31:39.816056Z",
     "shell.execute_reply.started": "2023-01-27T07:31:39.333561Z"
    }
   },
   "outputs": [],
   "source": [
    "kf_df = pd.read_csv('/kaggle/input/sq-services/kf_clean.csv')\n",
    "lca_df = pd.read_csv('/kaggle/input/sq-services/LCA_clean.csv')\n",
    "other_df = pd.read_csv('/kaggle/input/sq-services/other_clean.csv')\n",
    "kf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prepare df for alternate 2 and 3 approaches\n",
    "- tokenise text into sentences, remove duplicate sentences\n",
    "    - in the SQTalk forum, when person A replies to person B's comment, person A's comment will start with a word-for-word quote of person B's comment\n",
    "    - the strategy is to tokenise the text by sentences, then remove any repeated sentences to remove such repetitive quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:31:41.979848Z",
     "iopub.status.busy": "2023-01-27T07:31:41.979433Z",
     "iopub.status.idle": "2023-01-27T07:31:47.024343Z",
     "shell.execute_reply": "2023-01-27T07:31:47.023472Z",
     "shell.execute_reply.started": "2023-01-27T07:31:41.979813Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for kf dataset\n",
    "temp_df = []\n",
    "\n",
    "for text in kf_df['text']:\n",
    "    for sent in sent_tokenize(str(text)):\n",
    "        temp_df.append(sent)\n",
    "\n",
    "kf_sent_df = pd.DataFrame(data=temp_df, columns=['sent'])\n",
    "print(f\"kf_df had {kf_sent_df.shape[0]} rows\")\n",
    "kf_sent_df.drop_duplicates(inplace=True)\n",
    "print(f\"After removing duplicates, kf_df has {kf_sent_df.shape[0]} rows\")\n",
    "\n",
    "# for lca dataset\n",
    "temp_df = []\n",
    "\n",
    "for text in lca_df['text']:\n",
    "    for sent in sent_tokenize(str(text)):\n",
    "        temp_df.append(sent)\n",
    "\n",
    "lca_sent_df = pd.DataFrame(data=temp_df, columns=['sent'])\n",
    "print(f\"lca_df had {lca_sent_df.shape[0]} rows\")\n",
    "lca_sent_df.drop_duplicates(inplace=True)\n",
    "print(f\"After removing duplicates, lca_df has {lca_sent_df.shape[0]} rows\")\n",
    "\n",
    "# for other dataset\n",
    "temp_df = []\n",
    "\n",
    "for text in other_df['text']:\n",
    "    for sent in sent_tokenize(str(text)):\n",
    "        temp_df.append(sent)\n",
    "\n",
    "other_sent_df = pd.DataFrame(data=temp_df, columns=['sent'])\n",
    "print(f\"other_df had {other_sent_df.shape[0]} rows\")\n",
    "kf_sent_df.drop_duplicates(inplace=True)\n",
    "print(f\"After removing duplicates, other_df has {other_sent_df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reassign 'source' column, and combine into 1 dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:31:50.049897Z",
     "iopub.status.busy": "2023-01-27T07:31:50.049428Z",
     "iopub.status.idle": "2023-01-27T07:31:50.068036Z",
     "shell.execute_reply": "2023-01-27T07:31:50.066241Z",
     "shell.execute_reply.started": "2023-01-27T07:31:50.049858Z"
    }
   },
   "outputs": [],
   "source": [
    "kf_sent_df['source'] = 'kf'\n",
    "lca_sent_df['source'] = 'lca'\n",
    "other_sent_df['source'] = 'other'\n",
    "\n",
    "services_df = pd.concat([kf_sent_df, lca_sent_df, other_sent_df])\n",
    "services_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check for and resolve any NA values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:31:52.314857Z",
     "iopub.status.busy": "2023-01-27T07:31:52.314452Z",
     "iopub.status.idle": "2023-01-27T07:31:52.411959Z",
     "shell.execute_reply": "2023-01-27T07:31:52.410623Z",
     "shell.execute_reply.started": "2023-01-27T07:31:52.314827Z"
    }
   },
   "outputs": [],
   "source": [
    "print(services_df.isna().sum())\n",
    "\n",
    "# acceptable to drop 3 NA values out of 44k values\n",
    "services_df.dropna(inplace=True)\n",
    "# reset index, and drop old index\n",
    "services_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(services_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a 'kf' column: \n",
    "    - if value = 0, the source is others\n",
    "    - if value = 1, the source is kf\n",
    "    - if value = 2, the source is from LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:31:55.554971Z",
     "iopub.status.busy": "2023-01-27T07:31:55.553920Z",
     "iopub.status.idle": "2023-01-27T07:31:55.586679Z",
     "shell.execute_reply": "2023-01-27T07:31:55.585516Z",
     "shell.execute_reply.started": "2023-01-27T07:31:55.554927Z"
    }
   },
   "outputs": [],
   "source": [
    "services_df['y_true'] = services_df['source'].map({'other':0, 'kf': 1, 'lca': 2})\n",
    "print(services_df.head())\n",
    "services_df['y_true'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stem text and stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:31:58.154318Z",
     "iopub.status.busy": "2023-01-27T07:31:58.153904Z",
     "iopub.status.idle": "2023-01-27T07:31:58.159638Z",
     "shell.execute_reply": "2023-01-27T07:31:58.158513Z",
     "shell.execute_reply.started": "2023-01-27T07:31:58.154281Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:31:59.885352Z",
     "iopub.status.busy": "2023-01-27T07:31:59.884950Z",
     "iopub.status.idle": "2023-01-27T07:31:59.892102Z",
     "shell.execute_reply": "2023-01-27T07:31:59.890856Z",
     "shell.execute_reply.started": "2023-01-27T07:31:59.885312Z"
    }
   },
   "outputs": [],
   "source": [
    "def token_stem(sent):\n",
    "    result = []\n",
    "    list = word_tokenize(sent)\n",
    "    for word in list:\n",
    "        result.append(stemmer.stem(word))\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:32:16.834468Z",
     "iopub.status.busy": "2023-01-27T07:32:16.834035Z",
     "iopub.status.idle": "2023-01-27T07:33:43.024940Z",
     "shell.execute_reply": "2023-01-27T07:33:43.023716Z",
     "shell.execute_reply.started": "2023-01-27T07:32:16.834434Z"
    }
   },
   "outputs": [],
   "source": [
    "services_stem_df = services_df.copy()\n",
    "services_stem_df['sent'] = [token_stem(text) for text in services_df['sent']]\n",
    "services_stem_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add selected words to stopwords, taken from [\"SQTalk Abbreviations, Slangs, Definitions, Phrases\"](http://www.sqtalk.com/forum/forum/general/sqtalk-community/1010-) thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:36:39.579837Z",
     "iopub.status.busy": "2023-01-27T07:36:39.579284Z",
     "iopub.status.idle": "2023-01-27T07:36:39.596286Z",
     "shell.execute_reply": "2023-01-27T07:36:39.594858Z",
     "shell.execute_reply.started": "2023-01-27T07:36:39.579793Z"
    }
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(max_features = 500, stop_words = 'english') \n",
    "stem_stopwords = [stemmer.stem(word) for word in cvec.get_stop_words()]\n",
    "stem_stopwords.extend([stemmer.stem(word) for word in ['btw','iirc','imo','imho']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prepare untreated df for alternate 1 approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:36:48.045134Z",
     "iopub.status.busy": "2023-01-27T07:36:48.044546Z",
     "iopub.status.idle": "2023-01-27T07:36:48.106905Z",
     "shell.execute_reply": "2023-01-27T07:36:48.105697Z",
     "shell.execute_reply.started": "2023-01-27T07:36:48.045083Z"
    }
   },
   "outputs": [],
   "source": [
    "services_untreated_df = pd.concat([kf_df, lca_df, other_df])\n",
    "\n",
    "print(services_untreated_df.isna().sum())\n",
    "\n",
    "# acceptable to drop 3 NA values out of 44k values\n",
    "services_untreated_df.dropna(inplace=True)\n",
    "# reset index, and drop old index\n",
    "services_untreated_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(services_untreated_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a 'kf' column: \n",
    "    - if value = 0, the source is others\n",
    "    - if value = 1, the source is kf\n",
    "    - if value = 2, the source is from LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:36:50.288952Z",
     "iopub.status.busy": "2023-01-27T07:36:50.288150Z",
     "iopub.status.idle": "2023-01-27T07:36:50.313144Z",
     "shell.execute_reply": "2023-01-27T07:36:50.311532Z",
     "shell.execute_reply.started": "2023-01-27T07:36:50.288788Z"
    }
   },
   "outputs": [],
   "source": [
    "services_untreated_df['y_true'] = services_untreated_df['source'].map({'other':0, 'kf': 1, 'lca': 2})\n",
    "services_untreated_df['y_true'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- stem untreated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:36:52.351793Z",
     "iopub.status.busy": "2023-01-27T07:36:52.350129Z",
     "iopub.status.idle": "2023-01-27T07:38:31.834669Z",
     "shell.execute_reply": "2023-01-27T07:38:31.833191Z",
     "shell.execute_reply.started": "2023-01-27T07:36:52.351714Z"
    }
   },
   "outputs": [],
   "source": [
    "services_stem_untreated_df = services_untreated_df.copy()\n",
    "services_stem_untreated_df['text'] = [token_stem(text) for text in services_untreated_df['text']]\n",
    "services_stem_untreated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Model Fit & Predict\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Alternate 1\n",
    "### - using TFIDF and Multinomial NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:39:26.404525Z",
     "iopub.status.busy": "2023-01-27T07:39:26.403960Z",
     "iopub.status.idle": "2023-01-27T07:39:26.447025Z",
     "shell.execute_reply": "2023-01-27T07:39:26.445763Z",
     "shell.execute_reply.started": "2023-01-27T07:39:26.404477Z"
    }
   },
   "outputs": [],
   "source": [
    "X = services_stem_untreated_df['text']\n",
    "y = services_stem_untreated_df['y_true']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tokenise with Count Vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:39:35.463625Z",
     "iopub.status.busy": "2023-01-27T07:39:35.463089Z",
     "iopub.status.idle": "2023-01-27T07:39:38.465705Z",
     "shell.execute_reply": "2023-01-27T07:39:38.464334Z",
     "shell.execute_reply.started": "2023-01-27T07:39:35.463584Z"
    }
   },
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(max_features = 500, stop_words = stem_stopwords) \n",
    "X_train_cvec = tvec.fit_transform(X_train)\n",
    "X_test_cvec = tvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- instantiate and fit a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:39:42.695420Z",
     "iopub.status.busy": "2023-01-27T07:39:42.694737Z",
     "iopub.status.idle": "2023-01-27T07:39:42.750132Z",
     "shell.execute_reply": "2023-01-27T07:39:42.748715Z",
     "shell.execute_reply.started": "2023-01-27T07:39:42.695352Z"
    }
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "NB_model = ovr(nb).fit(X_train_cvec, y_train)  # using OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualise confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:39:44.416004Z",
     "iopub.status.busy": "2023-01-27T07:39:44.415465Z",
     "iopub.status.idle": "2023-01-27T07:39:44.720921Z",
     "shell.execute_reply": "2023-01-27T07:39:44.719875Z",
     "shell.execute_reply.started": "2023-01-27T07:39:44.415962Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = NB_model.predict(X_test_cvec)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Others', 'KrisFlyer', 'LCA'])\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- display precision, recall, f1-score of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:39:47.006601Z",
     "iopub.status.busy": "2023-01-27T07:39:47.006013Z",
     "iopub.status.idle": "2023-01-27T07:39:47.044902Z",
     "shell.execute_reply": "2023-01-27T07:39:47.043174Z",
     "shell.execute_reply.started": "2023-01-27T07:39:47.006551Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "# 0: other, 1: kf, 2: lca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- display the weighted average ROC AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:39:48.851921Z",
     "iopub.status.busy": "2023-01-27T07:39:48.851456Z",
     "iopub.status.idle": "2023-01-27T07:39:48.887000Z",
     "shell.execute_reply": "2023-01-27T07:39:48.885604Z",
     "shell.execute_reply.started": "2023-01-27T07:39:48.851884Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_prob = NB_model.predict_proba(X_test_cvec)\n",
    "\n",
    "roc_auc_score(y_test, y_pred_prob, multi_class='ovr', average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- weighted f1-score of KrisFlyer and LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:04.554010Z",
     "iopub.status.busy": "2023-01-27T07:40:04.552813Z",
     "iopub.status.idle": "2023-01-27T07:40:04.570930Z",
     "shell.execute_reply": "2023-01-27T07:40:04.569099Z",
     "shell.execute_reply.started": "2023-01-27T07:40:04.553959Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred, labels=[1,2], average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Alternate 2\n",
    "### - using removed duplicated sentences, CountVectoriser and Multinomial NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train-test split our df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:14.796034Z",
     "iopub.status.busy": "2023-01-27T07:40:14.794437Z",
     "iopub.status.idle": "2023-01-27T07:40:14.886764Z",
     "shell.execute_reply": "2023-01-27T07:40:14.885434Z",
     "shell.execute_reply.started": "2023-01-27T07:40:14.795973Z"
    }
   },
   "outputs": [],
   "source": [
    "X = services_stem_df['sent']\n",
    "y = services_stem_df['y_true']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tokenise with Count Vectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:17.117113Z",
     "iopub.status.busy": "2023-01-27T07:40:17.116535Z",
     "iopub.status.idle": "2023-01-27T07:40:20.089286Z",
     "shell.execute_reply": "2023-01-27T07:40:20.087929Z",
     "shell.execute_reply.started": "2023-01-27T07:40:17.117063Z"
    }
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(max_features = 500, stop_words = stem_stopwords) \n",
    "X_train_cvec = cvec.fit_transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- instantiate and fit a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:22.458120Z",
     "iopub.status.busy": "2023-01-27T07:40:22.457008Z",
     "iopub.status.idle": "2023-01-27T07:40:22.567654Z",
     "shell.execute_reply": "2023-01-27T07:40:22.565530Z",
     "shell.execute_reply.started": "2023-01-27T07:40:22.458065Z"
    }
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "NB_model = ovr(nb).fit(X_train_cvec, y_train)  # using OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualise confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:24.513524Z",
     "iopub.status.busy": "2023-01-27T07:40:24.512996Z",
     "iopub.status.idle": "2023-01-27T07:40:24.827925Z",
     "shell.execute_reply": "2023-01-27T07:40:24.826588Z",
     "shell.execute_reply.started": "2023-01-27T07:40:24.513486Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = NB_model.predict(X_test_cvec)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Others', 'KrisFlyer', 'LCA'])\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- display precision, recall, f1-score of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:27.251335Z",
     "iopub.status.busy": "2023-01-27T07:40:27.250795Z",
     "iopub.status.idle": "2023-01-27T07:40:27.319809Z",
     "shell.execute_reply": "2023-01-27T07:40:27.318111Z",
     "shell.execute_reply.started": "2023-01-27T07:40:27.251292Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "# 0: other, 1: kf, 2: lca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- display the weighted average ROC AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:28.881334Z",
     "iopub.status.busy": "2023-01-27T07:40:28.879797Z",
     "iopub.status.idle": "2023-01-27T07:40:28.957543Z",
     "shell.execute_reply": "2023-01-27T07:40:28.956012Z",
     "shell.execute_reply.started": "2023-01-27T07:40:28.881258Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_prob = NB_model.predict_proba(X_test_cvec)\n",
    "\n",
    "roc_auc_score(y_test, y_pred_prob, multi_class='ovr', average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- weighted f1-score of KrisFlyer and LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:31.030457Z",
     "iopub.status.busy": "2023-01-27T07:40:31.029923Z",
     "iopub.status.idle": "2023-01-27T07:40:31.054665Z",
     "shell.execute_reply": "2023-01-27T07:40:31.053335Z",
     "shell.execute_reply.started": "2023-01-27T07:40:31.030413Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred, labels=[1,2], average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Alternate 3\n",
    "### - using removed duplicated sentences, TFIDF and Multinomial NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tokenise with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:34.058653Z",
     "iopub.status.busy": "2023-01-27T07:40:34.058076Z",
     "iopub.status.idle": "2023-01-27T07:40:37.318657Z",
     "shell.execute_reply": "2023-01-27T07:40:37.316609Z",
     "shell.execute_reply.started": "2023-01-27T07:40:34.058604Z"
    }
   },
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(max_features = 500, stop_words = stem_stopwords)\n",
    "X_train_cvec = tvec.fit_transform(X_train)\n",
    "X_test_cvec = tvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- instantiate and fit a Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:38.990291Z",
     "iopub.status.busy": "2023-01-27T07:40:38.989821Z",
     "iopub.status.idle": "2023-01-27T07:40:39.095766Z",
     "shell.execute_reply": "2023-01-27T07:40:39.094577Z",
     "shell.execute_reply.started": "2023-01-27T07:40:38.990244Z"
    }
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "NB_model = ovr(nb).fit(X_train_cvec, y_train)  # using OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualise confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:41.936104Z",
     "iopub.status.busy": "2023-01-27T07:40:41.935602Z",
     "iopub.status.idle": "2023-01-27T07:40:42.228135Z",
     "shell.execute_reply": "2023-01-27T07:40:42.227026Z",
     "shell.execute_reply.started": "2023-01-27T07:40:41.936064Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = NB_model.predict(X_test_cvec)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Others', 'KrisFlyer', 'LCA'])\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- display precision, recall, f1-score of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:44.734828Z",
     "iopub.status.busy": "2023-01-27T07:40:44.733429Z",
     "iopub.status.idle": "2023-01-27T07:40:44.806319Z",
     "shell.execute_reply": "2023-01-27T07:40:44.804480Z",
     "shell.execute_reply.started": "2023-01-27T07:40:44.734766Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "# 0: other, 1: kf, 2: lca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- display the weighted average ROC AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:46.702438Z",
     "iopub.status.busy": "2023-01-27T07:40:46.701210Z",
     "iopub.status.idle": "2023-01-27T07:40:46.772794Z",
     "shell.execute_reply": "2023-01-27T07:40:46.771505Z",
     "shell.execute_reply.started": "2023-01-27T07:40:46.702350Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_prob = NB_model.predict_proba(X_test_cvec)\n",
    "\n",
    "roc_auc_score(y_test, y_pred_prob, multi_class='ovr', average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- weighted f1-score of KrisFlyer and LCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-27T07:40:48.621907Z",
     "iopub.status.busy": "2023-01-27T07:40:48.621074Z",
     "iopub.status.idle": "2023-01-27T07:40:48.646556Z",
     "shell.execute_reply": "2023-01-27T07:40:48.644574Z",
     "shell.execute_reply.started": "2023-01-27T07:40:48.621867Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score(y_test, y_pred, labels=[1,2], average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Remarks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-25T14:07:54.024785Z",
     "iopub.status.busy": "2023-01-25T14:07:54.023717Z",
     "iopub.status.idle": "2023-01-25T14:07:54.034088Z",
     "shell.execute_reply": "2023-01-25T14:07:54.032340Z",
     "shell.execute_reply.started": "2023-01-25T14:07:54.024736Z"
    }
   },
   "source": [
    "|                                     | Baseline Model<br>(from notebook 2) | Alternate 1<br>\\*Best performance\\* | Alternate 2 | Alternate 3 |\n",
    "|-------------------------------------|----------------|-------------|-------------|-------------|\n",
    "| Pre-processing | - Basic cleaning<br>- Stem        | - Basic cleaning<br>- Stem       | - Basic cleaning<br>- Stem<br>- Remove duplicated sentences | - Basic cleaning<br>- Stem<br>- Remove duplicated sentences |\n",
    "| Vectoriser     | CountVectoriser         | TFIDF                   | CountVectoriser                                   | TFIDF                                             |\n",
    "| Model          | Multinomial Naive Bayes | Multinomial Naive Bayes | Multinomial Naive Bayes                           | Multinomial Naive Bayes                           |\n",
    "| Macro-average ROC AUC            | 0.887          | 0.908       | 0.807       | 0.819       |\n",
    "| Macro-average f1-score (kf, lca) | 0.752          | 0.759       | 0.625       | 0.630       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Alternate 1 combination of preprocessing and vectoriser performed the best, and will be used for the next step of finding the best model\n",
    "<br>\n",
    "<br>\n",
    "- TFIDF had a slightly better performance than CountVectoriser (baseline vs alt 1, alt2 vs alt 3)\n",
    "<br>\n",
    "<br>\n",
    "- The removal of duplicated sentences seemed to have an adverse effect on model performance. This suggested that the quotes contain valuable key words that deserved to be emphasised (i.e. the comments that people usually reply to contain valuable key words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
